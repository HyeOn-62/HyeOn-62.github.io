---

title: cs231n Lecture 2
date : 2018-03-28
category: cs231n
use_math: true

---

# Lecture 2 : Image Classification pipeline

cs231n 두번째 강의에서는 Image Classification과 관련된 기본적인 얘기를 다룬다.

기본적으로 인간은 자연스럽게 사물을 보면 자연스럽게 그 사물을 인식하고 패턴을 파악해서 그 이미지가 무엇에 해당하는지 알 수 있다. 누가 굳이 가르쳐주지 않아도 자연스럽게 이루어지는 과정이다. 하지만 기계에게 이미지를 인식하게 하는 것은 조금 많이 어려운 일이다.

![](https://user-images.githubusercontent.com/40735375/50518986-11e88c00-0afc-11e9-93ed-a4e4112ad85d.png)

기계는 이미지를 일련의 숫자로 인식한다. 그레이 스케일의 경우에는 한 픽셀에 0부터 255의 값으로, RGB의 경우에는 한 픽셀에 0부터255의 값이 세개씩 할당된다. 한 이미지를 픽셀 하나하나의 모음으로 인식하는 것이다. 이러한 접근은 컴퓨터가 이미지를 인식하고 처리하는 데에는 매우 용이하지만, 인간이 이미지를 이해하는 방식과는 많이 동떨어져 있다. 

예를 들어, 피사체를 바라보는 각도가 바뀌게 되면 사람은 큰 무리 없이 두 화면이 동일한 피사체를 다른 각도에서 비추고 있다는 사실을 인식할 수 있다. 하지만 기계의 경우에는 완전히 다르다. 카메라의 각도가 변하게 되면 모든 픽셀의 위치가 변하게 되기에, 기계의 입장에서는 전혀 다른 숫자의 나열이 들어오게 되는 것이다. 이외에도 조명이 변화한달지, 피사체가 약간 변화한달지, 피사체의 일부분만 이미지에 들어난달지, 배경과 피사체의 색이 비슷해 구분이 어렵다던지, 이런 다양한 케이스에서도 이미지를 인식할 수 있도록 만드는 것은 쉬운 일이 아니다.

초기의 computer vision에서는 주어진 이미지에서 먼저 선을 찾고, 모서리를 찾아 이미지가 무엇인지를 인식하는 방법론을 취했다. 하지만 이러한 방법은 앞서 언급했던 다양한 문제 상황에 적절하게 대응하기가 힘들다. 그에 대한 대안으로 설명하는 것이 ***Data-Driven Approach***이다. 이는 일반적으로 우리가 알고 있는 deep learning보다는 좀 더 일반적이고 포괄적인 개념으로, 수많은 이미지 데이터에 대해서 레이블을 구해 데이터-레이블 쌍을 구하고, 그 데이터를 기반으로 classifier를 학습시켜 새로운 데이터에 대해서 classifier의 성능을 구하는 것을 의미한다. 앞으로 데이터를 기반으로 classifier를 학습시키는 과정을 `train`, 학습된 classifier를 이용해 새로운 데이터에 대해서 그 데이터의 레이블을 구하고 성능을 비교하는 과정을 `predict`이라고 통칭하겠다.

이번 강의에서 소개했던 첫번째 classifier는 **k - Nearest Neighbor** 이다.

#### 1. kNN

가상의 모델을 하나 생각해보자. 이 모델은 `train` 과정에서는 모든 데이터와 레이블을 기억하고, `predict` 과정에서는 기억한 모든 데이터를 한바퀴 쭉 돌면서 새로 들어온 데이터와 가장 비슷한 데이터의 레이블을 새로운 데이터의 레이블일 것이라고 예측한다. 이 때 '가장 비슷하다'는 비교 기준이 다양할 수 있다. 강의에서 소개하는 비교 기준은 거리 방식 두가지이다.

 1. L1 distance (*Manhattan distance*)
    
    
    $$
    d_1(I_1,I_2) = \sum_{p} |I_1^p-I_2^p|
    $$


- 여기에서 p는 모든 dimension을 의미한다. 예를 들어 I1과 I2가 각각 (1,1)과 (2,0)의 값을 가지는 좌표들이라고 하자. 그렇다면 두 좌표의 맨하튼 거리, 다시 말해서 L1 distance는 |1-2| + |1-0| 으로 2가 된다. 3차원, 4차원에서도 마찬가지이다. 상응하는 dimension에 대해서 차를 구하고 그 모든 차를 더해주면 된다.
- 이미지 데이터에서도 유사하게 거리를 구할 수 있다. 동일한 크기의 이미지에 대해서 pixel-wise로 차를 계산하고, 그 모든 차를 더해주면 두 이미지 데이터의 L1 distance를 구할 수 있다.
- 이러한 거리방식은 corrdinate system과 잘 맞기 때문에 벡터의 각 원소가 각각의 의미를 가질 때 주로 쓰인다. 

2. L2 distance (*Euclidean distance*)

$$
d_2(I_1,I_2) = \sqrt{\sum_{p} (I_1^p-I_2^p)^2}
$$

- 유클리드 거리는 우리가 일반적으로 알고 있는 거리를 의미한다. 위의 예제와 같이 I1과 I2가 각각 (1,1)과 (2,0)의 값을 가지는 좌표라면, 거리는 $\sqrt{|1-2|^2 + |1-0|^2}$ 로, $\sqrt{2}$ 가 된다. 이 역시 3차원 이상의 dimension에 확장될 수 있다.

- 이러한 거리방식은 어떠한 공간에서 feature가 의미를 가질 때 주로 사용된다.


하지만 이렇게  `train` 과정에서 모든 데이터를 기억하고 -  `O(1)`  `predict`과정에서 일일히 train data를 확인하면서 -  `O(N)` 레이블을 구하는 과정은 classifier의 의미와는 잘 맞지 않는다. 우리가 원하는 classifier는 학습할 때 오래 걸리더라도 예측할 때는 바로바로 레이블을 출력하기를 원하기 때문이다.



그렇다면 가장 가까운 k개의 거리에 있는 데이터를 살펴본다고 했을 때, k의 수가 달라지면 어떤 식으로 분류하는 decision area가 변화하게 될까?

![image](https://user-images.githubusercontent.com/40735375/50537854-fc7d6b80-0ba8-11e9-9045-937ce1884a5c.png)

먼저 k=1 일 때의 decision area를 확인해보면, 가운데의 초록색 범위 내에 작게 노란색 범위가 끼어있는 것을 확인할 수 있다. 하지만 가장 가까운 거리에 있는 점의 레이블이 노란색이더라도, 전반적인 데이터의 분포를 봤을 때는 초록색 내부의 범위 역시 초록색으로 칠해지는 것이 더 합리적이다. 하지만 가장 가까운 하나의 점(아웃라이어)때문에 범위가 부적절하게 결정되는 것이다. 또한 왼쪽의 빨강-파랑 범위의 경계를 보면 경계가 들쑥날쑥한 것을 확인할 수 있다. 이 역시 하나의 데이터에 의존해서 미세한 변화에도 쉽게 영향을 받게되는 것이다.

k=3일때를 확인해보자. 이 경우에는 초록색의 영역 한 가운데에 있던 노란색의 영역이 사라진 것을 확인할 수 있다. 그럼에도 아직 빨강-파랑의 경계는 들쑥날쑥한 것을 알 수 있다. 하지만 k를 더 증가시켜 k가 5일때를 보면, 들쑥날쑥하던 경계도 사라진 것을 확인할 수 있다.

이렇듯 k의 값을 무엇으로 설정하느냐에 따라서 모델이 내놓는 결과 값이 달라지게 된다. 그리고 앞서 얘기했던 두 가지의 거리 공식 중에서도 어떤 거리 공식을 사용하느냐에 따라서 결과 값이 달라지게 된다. 이렇듯 데이터로부터 학습을 통해 얻어지는 파라미터들이 아니라, 알고리즘과 데이터의 성격에 따라서 우리가 결정해야 하는 파라미터들을 *hyperparameters*라고 한다. 무조건 완전하게 좋은 하이퍼파라미터는 존재하지 않는다. 문제의 성격에 따라서 적절한 하이퍼파라미터가 매우 달라지기 때문에 여러가지를 실험해보고 가장 성능이 좋은 하이퍼파라미터를 선택해야 한다.

하지만 각 픽셀간의 거리를 구한 후에 그 거리의 총합이 적을 수록 이미지가 비슷할 것이라는 추론은 언뜻 듣기에도 합리적이지 않다. kNN의 아이디어 자체가 이미지 데이터의 특성과는 거리가 멀기 때문에 kNN으로 이미지를 분류하지는 않는다. 또한 test를 할 때에 시간이 너무 오래 걸린다는 것과, 주어진 데이터의 dimension에 따라서 필요한 데이터의 양에 exponential하게 증가한다는 이유 등이 있다.



#### 2. Linear Classification

Linear classifier는 Neural Network의 기본이 되는 구조 중 하나이다. 또한 parametric model의 기초이기도 한데, linear classifier의 경우에는 학습을 통해서 parameter가 정해진다는 점이 앞서 배웠던 kNN과는 다르다. 

$$
f(x,W) =Wx+b
$$

예를 들어 32x32 픽셀 사이즈를 가지는 RGB이미지를 10개의 클래스로 분류하는 작업을 시도한다고 하자. 이 때 우리가 최종적으로 구하려고 하는 것은 10개의 클래스에 대한 값이므로  $f(x,W)$ 는 10x1의 크기가 될 것이다. 그리고 인풋은 이미지 한 장이므로 3072(32\*32\*3)x1 이다. 따라서 $W$의 적절한 크기는 10x3072가 된다. 행렬의 곱셉을 생각해보면 이해가 쉬울 것이다. 그리고 $b$ 는 biased term으로 $f(x,W)$ 과 동일한 10x1의 크기를 가진다.

![image-20181230014627290](https://user-images.githubusercontent.com/40735375/50540509-57798780-0bd6-11e9-8be9-dc93c7a030f2.png)

위의 사진을 보면 좀 더 이해가 쉬울 것이다. 10개의 클래스를 3개로, 32x32의 RGB 이미지를 2x2의 그레이스케일 이미지로 축약한 형태이다.



### Spliting data

1. 모두 training set으로 사용하기

   - train 할 때 이용한 기존의 데이터 셋에 대해서는 완벽하게 작동하겠지만, 새로운 데이터에 대해서는 잘못 예측할 확률이 높아지기 때문에 이러한 방식으로 데이터를 나누는 것은 좋지 않다. (overfitting이 일어날 확률이 높아진다.)

2. Training set과 testing set으로 나누기

   - 1번보다는 나은 방식이지만, testing set에 대한 예측결과를 보고 하이퍼파라미터를 조절하기 때문에 testing set 역시 학습에 이용하는 셈이 된다. 따라서 더 이상 testing set에 대한 결과가 완전히 새로운 데이터에 대한 결과를 대표하지 못하게 된다.

3. Training set, testing set, 그리고 validation set으로 나누기

   - Training set으로는 학습을 시키고, validation set으로는 결과를 통해 하이퍼파라미터를 조절하고, testing set에 대해서는 단 한번만 실험한 후 성능을 판단한다.

   - 각 데이터 셋들에 대해서 identically distributed 되었다는 가정이 필요하며, 잘 섞인 상태여야 한다.

4. k fold cross validation

   - 먼저 데이터를 training set과 testing set으로 나눈 후에, training set을 k개로 나누어서 각각의 조각에 대해서 한번씩 validation으로 사용하면서 학습을 진행한다.
   - 데이터 셋의 절대적인 양이 적거나, unbalanced data일 경우 성능이 좋아질 수 있다. 그러나 딥러닝에서는 자주 쓰이지 않는다. 



##### Reference

- [Cs231n Lecture 2](http://cs231n.stanford.edu/slides/2018/cs231n_2018_lecture02.pdf)



Cs231n 강의를 듣고 공부한 것을 정리한 글입니다. 오개념이나 잘못 정리한 것이 있으면 알려주세요 :)
